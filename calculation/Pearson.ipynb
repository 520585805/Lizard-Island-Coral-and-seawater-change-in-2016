{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e5f594",
   "metadata": {},
   "source": [
    "# Pearson Correlation Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbbad4",
   "metadata": {},
   "source": [
    "This part of calculation aims to show the relation between these three factors: 1) temperature, 2)pH, 3)salinity. Then, the final data will help us to understand the truth of the synergy revealed by Geodetector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset, num2date\n",
    "\n",
    "import cmocean\n",
    "\n",
    "import seaborn as sns\n",
    "import pymannkendall as mk\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,7)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad0dfe",
   "metadata": {},
   "source": [
    "First, let us extract the data from 2011 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee379827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85420bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define starting and ending date of the netcdf file we want to load \n",
    "# delta = relativedelta(months=+1)\n",
    "# selectedDepthIndex = -1\n",
    "# rf = pd.read_csv('totalpoints.csv')\n",
    "# i = 26\n",
    "\n",
    "# while i < 50:\n",
    "#     site_lat = rf.Latitude[i+1] \n",
    "#     site_lon = rf.Longitude[i+1]\n",
    "#     step = True\n",
    "#     start_date = dt.date(2011, 1, 1)\n",
    "#     end_date = dt.date(2016, 12, 1)\n",
    "#     while start_date <= end_date:  \n",
    "   \n",
    "#         # Read individual file from the OpeNDAP server\n",
    "#         netCDF_datestr = str(start_date.year)+'-'+format(start_date.month, '02')\n",
    "#         inputFile = \"https://thredds.ereefs.aims.gov.au/thredds/dodsC/s3://aims-ereefs-public-prod/derived/ncaggregate/ereefs/gbr4_v2/monthly-monthly/EREEFS_AIMS-CSIRO_gbr4_v2_hydro_monthly-monthly-\"+netCDF_datestr+\".nc\"\n",
    "#         inputFile2 = \"https://thredds.ereefs.aims.gov.au/thredds/dodsC/s3://aims-ereefs-public-prod/derived/ncaggregate/ereefs/GBR4_H2p0_B3p1_Cq3b_Dhnd/monthly-monthly/EREEFS_AIMS-CSIRO_GBR4_H2p0_B3p1_Cq3b_Dhnd_bgc_monthly-monthly-\"+netCDF_datestr+\".nc\"\n",
    "#         nc_data = Dataset(inputFile, 'r')\n",
    "#         ncdata = nc_data.variables\n",
    "#         nc_data2 = Dataset(inputFile2, 'r')\n",
    "#         ncdata2 = nc_data2.variables\n",
    "#         start_date += delta    \n",
    "        \n",
    "#         # Get parameters values for each single file\n",
    "#         if step:\n",
    "#             lat = ncdata['latitude'][:].filled(fill_value=0.)\n",
    "#             lon = ncdata['longitude'][:].filled(fill_value=0.)\n",
    "#             times = ncdata['time'][:]\n",
    "#             selectedLatIndex = find_nearest(lat,site_lat)\n",
    "#             selectedLonIndex = find_nearest(lon,site_lon)\n",
    "#             temperature = nc_data.variables['temp'][:,selectedDepthIndex, selectedLatIndex, selectedLonIndex]\n",
    "#             salinity = nc_data.variables['salt'][:,selectedDepthIndex, selectedLatIndex, selectedLonIndex]\n",
    "#             pH = nc_data2.variables['PH'][:,selectedDepthIndex, selectedLatIndex, selectedLonIndex]\n",
    "#         else:\n",
    "#             days = ncdata['time'][:]\n",
    "#             times = np.hstack((times,days))\n",
    "#             dailyTemp = nc_data.variables['temp'][:,selectedDepthIndex, selectedLatIndex, selectedLonIndex]\n",
    "#             temperature = np.hstack((temperature,dailyTemp))\n",
    "#             dailySalt = nc_data.variables['salt'][:,selectedDepthIndex, selectedLatIndex, selectedLonIndex]\n",
    "#             salinity = np.hstack((salinity,dailySalt))\n",
    "#             dailyPH = nc_data2.variables['PH'][:,selectedDepthIndex, selectedLatIndex, selectedLonIndex]\n",
    "#             pH = np.hstack((pH,dailyPH)) \n",
    "#         step = False\n",
    "\n",
    "#     time = pd.to_datetime(times[:],unit='D',origin=pd.Timestamp('1990-01-01'))\n",
    "#     # Create a pandas dataframe containing the information from all the files\n",
    "#     df = pd.DataFrame(\n",
    "#         data={\n",
    "#             \"salinity\": salinity,\n",
    "#             \"temperature\": temperature,\n",
    "#             \"pH\": pH\n",
    "#         }\n",
    "#     )\n",
    "#     name = \"REEF\" + str(i+1)+ \".csv\"\n",
    "#     # Store these informations on a file in case you want to reuse them later on without having to \n",
    "#     # rerun this cell...\n",
    "#     df.to_csv(\n",
    "#             name,\n",
    "#             columns=[\"salinity\", \"temperature\",\"pH\"],\n",
    "#             sep=\" \",\n",
    "#             index=False,\n",
    "#             header=1,\n",
    "#         )\n",
    "        \n",
    "    \n",
    "    \n",
    "#     print('file'+str(i+1) + ' has been filled')\n",
    "#     i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = pd.read_csv('REEF1.csv',sep=' ')\n",
    "tsp = prs.corr()\n",
    "print(tsp.temperature[0])\n",
    "print(tsp.pH[0])\n",
    "print(tsp.pH[1])\n",
    "tsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15242e34",
   "metadata": {},
   "source": [
    "It is successful, now find the range of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbf7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final1 = []\n",
    "final2 = []\n",
    "final3 = []\n",
    "for item in range(50):\n",
    "    prs = pd.read_csv('REEF'+ str(item + 1) + '.csv',sep=' ')\n",
    "    tsp = prs.corr()\n",
    "    k = tsp.temperature[0]\n",
    "    l = tsp.pH[0]\n",
    "    m = tsp.pH[1]\n",
    "    final1.append(k)    #salinity and temperature\n",
    "    final2.append(l)    #salinity and pH\n",
    "    final3.append(m)    #pH and temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f70e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = ['corr_of_salttemp']\n",
    "Final1 = pd.DataFrame(columns = name1, data = final1)\n",
    "# Final1.to_csv('salttemp.csv')\n",
    "\n",
    "name2 = ['corr_of_saltpH']\n",
    "Final2 = pd.DataFrame(columns = name2, data = final2)\n",
    "# Final2.to_csv('saltpH.csv')\n",
    "\n",
    "name3 = ['corr_of_pHtemp']\n",
    "Final3 = pd.DataFrame(columns = name3, data = final3)\n",
    "# Final3.to_csv('pHtemp.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b7f7a",
   "metadata": {},
   "source": [
    "Then, calculate Pearson Correlation Index of the 'temp', 'salt' and 'ph' at each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5316da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The range of correlation of salt and temp: '+ str(min(Final1.corr_of_salttemp))+ ' and ' + str(max(Final1.corr_of_salttemp)))\n",
    "print ('The range of correlation of salt and pH: '+ str(min(Final2.corr_of_saltpH))+ ' and ' + str(max(Final2.corr_of_saltpH)))\n",
    "print ('The range of correlation of pH and temp: '+ str(min(Final3.corr_of_pHtemp))+ ' and ' + str(max(Final3.corr_of_pHtemp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('salttemp.csv')\n",
    "# df2 = pd.read_csv('saltpH.csv')\n",
    "# df3 = pd.read_csv('pHtemp.csv')\n",
    "# outfile = pd.merge (df1, df2, df3) #, left_on = 'lable', right_on = '0'\n",
    "# outfile.to_csv('totalcorr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"按列合并公式\"\n",
    "# df1 = pd.read_csv()\n",
    "# df2\n",
    "# outfile = pd.merge (df1, df2) #, left_on = 'lable', right_on = '0'\n",
    "# outfile.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb6f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = r'calculation\\reefs'\n",
    "# savefile_path = r'calculation'\n",
    "# savefile_name = r'allreefs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir (folder_path)\n",
    "# file_list = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c625eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
